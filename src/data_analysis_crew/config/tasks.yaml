# ---------------------------------------------------------------------------
#  1  LOAD ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
load_data:
  description: >
    Load the CSV dataset using the exact *literal* path in `{dataset_path}`.
    ‚ö†Ô∏è Do **not** search or list directories.

    Use pandas to:
      ‚Ä¢ read the file  
      ‚Ä¢ `print()` shape and column names  
      ‚Ä¢ report missing-value counts and inferred dtypes  

    Dataset Path (string): **{dataset_path}**
  expected_output: >
    - Dataset shape  
    - `dtype_map` (column ‚Üí dtype)  
    - `missing_values` (column ‚Üí #missing)  
    - Path actually read/written
  agent: data_engineer

# ---------------------------------------------------------------------------
#  2  CLEAN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
clean_data:
  description: >
    Tidy up the raw dataset.

    ‚Ä¢ Call the tool:
      `load_or_clean(raw_path="{dataset_path}", cleaned_path="knowledge/diabetes_cleaned.csv")`
    ‚Ä¢ If the cleaned file exists, it‚Äôll be re-used.
    ‚Ä¢ If **knowledge/diabetes_cleaned.csv** exists ‚Üí just load it, gather
      metadata, and return ‚Äì **do not** re-clean.  
    ‚Ä¢ Else ‚Üí read **knowledge/diabetes.csv**, normalise column names
      (lower-snake-case), fix missing values / constants, then save to the
      same cleaned path.

    Always `print()` the cleaned file path as **the first line of STDOUT** so
    the Code-Interpreter tool captures it.

    Helper available:

    ```python
    from data_analysis_crew.tools import load_or_clean
    df = load_or_clean()            # ‚Üê re-uses cache or cleans afresh
    ```

    After cleaning assemble the `CleanedDataOutput` fields:
      ‚Ä¢ cleaned_path  
      ‚Ä¢ final_features / numeric_features / categorical_features  
      ‚Ä¢ dropped_columns / imputation_summary
  expected_output: >
    1  First STDOUT line ‚Üí `knowledge/diabetes_cleaned.csv`  
    2  Markdown block:
       ‚Äì cleaning steps  
       ‚Äì final feature √ó dtype table  
       ‚Äì post-clean missing-value summary
  agent: data_engineer
  context: [load_data]

# ---------------------------------------------------------------------------
#  3  EXPLORE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
explore_data:
  description: >
    Perform an exploratory analysis of the cleaned dataset.

    Inputs (already in context):
      ‚Ä¢ Cleaned file ‚Üí `cleaned_path`  
      ‚Ä¢ Numeric cols ‚Üí `numeric_features`  
      ‚Ä¢ Categorical ‚Üí `categorical_features`

    When you call the Code Interpreter, include
    {
      "code": "
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    from pathlib import Path

    df = pd.read_csv('knowledge/diabetes_cleaned.csv')

    # 1) Descriptive statistics
    stats = df.describe().to_string()
    print(stats)

    # 2) Example plot directory
    plots_dir = Path('output/plots'); plots_dir.mkdir(parents=True, exist_ok=True)

    # Histogram for each numeric column
    for col in df.select_dtypes('number').columns:
        df[col].hist()
        plt.title(col)
        filename = "{}_hist.png".format(col)
        plt.savefig(plots_dir / filename)
        plt.clf()

    # 3) Correlation heat-map
    plt.figure(figsize=(8,6))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
    plt.tight_layout()
    heat_path = plots_dir / 'correlation_heatmap.png'
    plt.savefig(heat_path)
    print("Heat-map saved ‚Üí {}".format(heat_path))

    # ALWAYS finish with a print so the tool
    # has something to capture as ‚Äúfinal result‚Äù
    print('EDA script finished')
    ",
      "libraries_used": ["pandas", "matplotlib", "seaborn"]
    }.

    Tasks:
      1. Descriptive statistics (`df.describe()`; include categoricals)  
      2. Visualise distributions / relationships  
      3. Compute correlation matrix, list the top correlations with the target,
         flag outliers & anomalies.

    You **must** save **‚â• 3** PNGs into **{output_dir}/plots/**.
  expected_output: >
    Markdown report with:
      ‚Ä¢ embeds / links for the saved plots: <img src="output/plots/correlation_heatmap.png" width="600" />
      ‚Ä¢ table of top correlations  
      ‚Ä¢ notes on anomalies / biases / outliers
  agent: data_analyst
  context: [] # alternative: clean_data

# ---------------------------------------------------------------------------
#  4  FEATURE SELECTION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
select_features:
  description: >
    Select the strongest predictors for:

        {request}

    Use:
      ‚Ä¢ `top_correlations` (from EDA)  
      ‚Ä¢ `statistical_notes`

    Decide whether the prediction target is categorical or numeric:
      ‚Üí return `"classification"` or `"regression"`.

    Deliver:
      ‚Ä¢ `top_features` ‚Äì list & rationale  
      ‚Ä¢ `problem_type` ‚Äì classification / regression (+ why)
  expected_output: >
    Markdown brief:
      ‚Äì chosen features + justification  
      ‚Äì inferred problem type + explanation
  agent: data_analyst
  context: [explore_data]

# ---------------------------------------------------------------------------
#  5  MODEL BUILDING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
build_predictive_model:
  description: >
    Train multiple predictive models using the cleaned dataset, 
    compare them, and select the best based on validation performance.

    üõ†Ô∏è Tool to call:
    `build_predictive_model(data=cleaned_path, out_dir="{output_dir}", problem_type=problem_type, tuning=True)`

    ‚úÖ The tool will automatically:
      - Try all appropriate models:
          ‚Ä¢ classification: random_forest, logistic_reg, svm, knn, gbt  
          ‚Ä¢ regression:     random_forest, linear_reg, svm, gbt
      - Run GridSearchCV if `tuning=True` (default off)
      - Pick the best-performing model (F1 or R¬≤)
      - Save:
          ‚Ä¢ `output/model-report.json` (type, target, metrics, plots, summary)  
          ‚Ä¢ `output/technical-metrics.md`  
          ‚Ä¢ Visualizations to `output/plots/`
      - Include `all_model_scores` for dashboard bar chart use

    üõë Do **not** hard-code or guess the model name. The tool handles selection.

    For all embedded plots in markdown, use:
    <img src="plots/feature_importances.png" width="600" />
  expected_output: >
    - `output/model-report.json` with selected model, metrics, summary, paths
    - `output/plots/feature_importances.png` (+ confusion_matrix.png if classification)  
    - `output/technical-metrics.md`
  agent: model_builder
  context: [clean_data, select_features]


# ---------------------------------------------------------------------------
#  6  EXECUTIVE SUMMARY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
summarize_findings:
  description: >
    Craft an executive-level summary for non-technical stakeholders.

    Use:
      - `model_type`, `metrics`, `feature_importance_path`, 
      `output/technical-metrics.md` (from model_builder).
      - earlier narratives and outputs if helpful.

    Must include:
      - 2-3 sentence plain-language overview  
      - 3-5 bullet key insights  
      - a one-sentence recommendation  
      - embedded feature-importance image:
          <img src="plots/feature_importances.png" width="600" />
  expected_output: >
    Markdown file `output/final-insight-summary.md` with all of the above.
  agent: insight_reporter
  context: [build_predictive_model]
  output_file: output/final-insight-summary.md


# ---------------------------------------------------------------------------
#  7  LAUNCH DASHBOARD üöÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
launch_dashboard:
  description: >
    Launch the Streamlit dashboard.

    Call this inside the Code Interpreter:
    ```python
    import subprocess, time, webbrowser

    subprocess.Popen(["streamlit", "run", "dashboard.py"])
    time.sleep(3)
    webbrowser.open("http://localhost:8501")
    print("Dashboard launched on http://localhost:8501")
    ```
  expected_output: >
    A message confirming the dashboard URL, e.g.:
    "Dashboard launched on http://localhost:8501"
  agent: insight_reporter
  context: [summarize_findings]