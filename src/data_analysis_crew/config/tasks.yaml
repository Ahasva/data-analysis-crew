# ============================================================================
#  DATA ANALYSIS CREW - TASK DEFINITIONS (refined and production-grade)
# ============================================================================

# 1. LOAD RAW CSV
load_data:
  description: |
    Load the dataset from "{raw_path}" and extract core metadata and write this to "output/{file_name}_metadata.json":
    - DataFrame shape (rows, columns)
    - List of column names
    - Dictionary of missing values per column
    - Dictionary of data types per column

    Use Python and pandas to compute this information (via CodeInterpreterTool):
    ```python
    import pandas as pd
    df = pd.read_csv("{raw_path}")
    print(df.shape)
    print(df.columns.tolist())
    print(df.isnull().sum().to_dict())
    print(df.dtypes.astype(str).to_dict())
    ```

    ðŸ’¡ Save results as structured JSON (not CSV) to the "output/" folder.
  expected_output: |
    JSON dictionary including:
    ```json
    {
      "shape": [int, int],
      "columns": [str, ...],
      "missing": {column: int, ...},
      "dtypes": {column: dtype_str, ...}
    }
    ```
  agent: data_engineer
  output_file: "{output_dir}/{file_name}_metadata.json"

# 2. CLEAN DATA (outputs structured CSV + metadata JSON/MD)
clean_data:
  description: |
    Clean the raw dataset at "{raw_path}".

    Tasks:
    - Load CSV
    - Normalize column names (lowercase, replace spaces with underscores)
    - Handle missing values intelligently (drop or fill)
    - Save cleaned data to "{cleaned_path}" as CSV:
      ```python
      import pandas as pd
      df = pd.read_csv("{raw_path}")
      df.to_csv("{cleaned_path}", index=False)
      ```

    Additionally:
    - Extract metadata:
      - Final features (columns after cleaning)
      - Categorical and numeric feature types
      - Dropped columns
      - Imputation strategy used
    - Save metadata to:
      - JSON: "{summary_path_json}"
      - Markdown: "{summary_path_md}"

    âœ… Ensure:
    - Cleaned CSV is ML-ready (no metadata)
    - Metadata is saved separately as human + machine-readable files
    - Return confirmation of the process
  expected_output: |
    - Cleaned CSV at "{cleaned_path}"
    - Cleaning summary saved to:
      - "{output_dir}/{file_name}_cleaning_summary.json"
      - "{output_dir}/{file_name}_cleaning_summary.md"
    - JSON response should look like:
      ```json
      {
        "cleaned_path": "{cleaned_path}",
        "summary_path_json": "{output_dir}/{file_name}_cleaning_summary.json",
        "summary_path_md": "{output_dir}/{file_name}_cleaning_summary.md",
        "final_features": [...],
        "categorical_features": [...],
        "numeric_features": [...],
        "dropped_columns": [...],
        "imputation_summary": {...},
        "summary_markdown": "..."
      }
      ```
  agent: data_engineer
  context: [load_data]
  output_file: "{output_dir}/{file_name}_cleaning_summary.json"

# 3. EXPLORE DATA (EDA)
explore_data:
  description: |
    Perform exploratory data analysis (EDA) on the cleaned dataset "{cleaned_path}".

    Include:
    - `df.describe(include="all")` and `df.info(verbose=True)` summary
    - Visualize distributions of numeric features
    - Generate a correlation heatmap
    - Identify outliers, collinearity, and missing values
    - Distribution plots

    - Use approved libraries from: {available_libraries}; use other libraries, if necessary
    
    Save at least 3 plots to "{plot_path}" and embed them in a Markdown report with `<img src="..."/>`.
    Further list:
    - Top correlations
    - Visuals
    - Bullet-point insights

  expected_output: |
    Markdown report (.md file) with:
    - 3â€“5 plots (`<img src="..."/>`)
    - Key correlations and data trends with the target variable
    - Insightful commentary: Bullet point summary (3â€“5 key findings)
  agent: data_analyst
  context: [clean_data]
  output_file: "{output_dir}/exploration_report.md"

# 4. SELECT FEATURES
select_features:
  description: |
    Use EDA results and the user's request: "{request}", to:
    - Identify Machine Learning problem type: classification or regression
    - Select top predictive features and target variable
    - Justify selection based on correlations and domain logic and further: 
      - outliers, distributions, missingness, descriptive statistics, variable type, anomalies, missing values etc.

    Support with:
    - Metrics: "{classification_metrics}", "{regression_metrics}"
    - Feature distributions and data types
  expected_output: |
    JSON structure:
    ```json
    {
      "top_features": [str, ...],
      "target_variable": str,
      "problem_type": "classification" | "regression",
      "explanation": str
    }
    ```
  agent: data_analyst
  context: [explore_data]

# 5. BUILD MODEL
build_predictive_model:
  description: |
    Train and evaluate Machine Learning models using cleaned data from "{cleaned_path}".

    Steps:
    - Determine problem type from context (classification or regression)
    - Use suitable models from "{available_models}"
    - Save:
      - Model summary to "{output_dir}/model-report.json"
      - Technical metrics to "{output_dir}/technical-metrics.md"
      - Visualizations to "{plot_path}/..."
    Visuals (plots) usually include: ROC curve, Feature importance, Confusion matrix etc.
  expected_output: |
    - JSON report: "{output_dir}/model-report.json"
    - Model performance plots in "{plot_path}/...", e.g. "{plot_path}/feature_importance.png"
    - Markdown summary: "{output_dir}/technical-metrics.md"
  agent: model_builder
  context: [clean_data, select_features]

# 6. SUMMARY REPORT
summarize_findings:
  description: |
    Generate an executive-level summary of the modeling results:
    - Summarize model choice, model performance and evaluation
    - Embed visuals from previous steps (at least one, e.g. `<img src="..." width="480"/>`)
    - Highlight 3â€“5 key insights
    - Conclude with a business-ready recommendation

    Use metrics from:
      - Classification: {classification_metrics}
      - Regression: {regression_metrics}

  expected_output: |
    Markdown file at "{output_dir}/final-insight-summary.md" containing:
    - Executive summary (at least 2â€“3 sentence narrative overview of what the data reveals; 
    what analysis was performed; what model was selected and why it was selected)
    - Key insights (at least 3-5 bullet points, which summarize important findings, correlations, etc.)
    - Recommendation (clear, actionable next steps)
    - Embedded plots (use relative paths)
    - Metrics summary table
    (Use a header structure: ## âœ…)
  agent: insight_reporter
  context: [build_predictive_model]
  output_file: "{output_dir}/final-insight-summary.md"

# 7. CHECKLIST VALIDATION
validate_summary:
  description: |
    Validate the summary at "{output_dir}/final-insight-summary.md".

    Checklist:
    - Executive summary present?
    - Key insights in bullet format?
    - Visuals embedded?
    - Metrics mentioned?
    - Recommendation included?

    - Confirm all required sections are present
    - Flag missing components (plots, metrics, summaries) for each, mark âœ… present or âŒ missing

    Save results as:
    - Markdown checklist
    - Text log to "{output_dir}/summary_qc_log.txt"

  expected_output: |
    - Markdown checklist with âœ…/âŒ for each item
    - Checklist saved as: "{output_dir}/summary_qc_log.txt"
  agent: quality_checker
  context: [summarize_findings]
  output_file: "{output_dir}/final-report-checklist.md"

# 8. LAUNCH DASHBOARD
launch_dashboard:
  description: |
    Start the Streamlit dashboard by executing python code: launch_dashboard(path="{dashboard_file}", port=8501)

    âš ï¸ Do not modify the file manually. Ensure dependencies are installed.
  expected_output: >
    "Dashboard launched on http://localhost:8501"
  agent: insight_reporter
  context: [validate_summary]