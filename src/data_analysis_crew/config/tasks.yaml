# ---------------------------------------------------------------------------
#  1  LOAD ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
load_data:
  description: >
    Load the CSV dataset using the exact *literal* path in `{dataset_path}`.
    ‚ö†Ô∏è Do **not** search or list directories.

    Use pandas to:
      ‚Ä¢ read the file  
      ‚Ä¢ `print()` shape and column names  
      ‚Ä¢ report missing-value counts and inferred dtypes  

    Dataset Path (string): **{dataset_path}**
  expected_output: >
    - Dataset shape  
    - `dtype_map` (column ‚Üí dtype)  
    - `missing_values` (column ‚Üí #missing)  
    - Path actually read/written
  agent: data_engineer

# ---------------------------------------------------------------------------
#  2  CLEAN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
clean_data:
  description: >
    Tidy up the raw dataset.

    ‚Ä¢ Call the tool:
      `load_or_clean(raw_path="{dataset_path}", cleaned_path="knowledge/diabetes_cleaned.csv")`
    ‚Ä¢ If the cleaned file exists, it‚Äôll be re-used.
    ‚Ä¢ If **knowledge/diabetes_cleaned.csv** exists ‚Üí just load it, gather
      metadata, and return ‚Äì **do not** re-clean.  
    ‚Ä¢ Else ‚Üí read **knowledge/diabetes.csv**, normalise column names
      (lower-snake-case), fix missing values / constants, then save to the
      same cleaned path.

    Always `print()` the cleaned file path as **the first line of STDOUT** so
    the Code-Interpreter tool captures it.

    Helper available:

    ```python
    from data_analysis_crew.tools import load_or_clean
    df = load_or_clean()            # ‚Üê re-uses cache or cleans afresh
    ```

    After cleaning assemble the `CleanedDataOutput` fields:
      ‚Ä¢ cleaned_path  
      ‚Ä¢ final_features / numeric_features / categorical_features  
      ‚Ä¢ dropped_columns / imputation_summary
  expected_output: >
    1  First STDOUT line ‚Üí `knowledge/diabetes_cleaned.csv`  
    2  Markdown block:
       ‚Äì cleaning steps  
       ‚Äì final feature √ó dtype table  
       ‚Äì post-clean missing-value summary
  agent: data_engineer
  context: [load_data]

# ---------------------------------------------------------------------------
#  3  EXPLORE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
explore_data:
  description: >
    Perform an exploratory analysis of the cleaned dataset.

    Inputs (already in context):
      ‚Ä¢ Cleaned file ‚Üí `cleaned_path`  
      ‚Ä¢ Numeric cols ‚Üí `numeric_features`  
      ‚Ä¢ Categorical ‚Üí `categorical_features`

    The analysis must include:
      1. Descriptive statistics (use `df.describe(include="all")`)  
      2. Visualise distributions using histograms for each numeric feature  
      3. Correlation heatmap between numerical features  
      4. Save ‚â• 3 visualizations into `{plot_path}/`  
      5. Print meaningful summary insights

    üí° You have access to:
      - pandas, seaborn, matplotlib, pathlib
      - `CodeInterpreterTool` will handle execution

    Ensure the directory `{plot_path}/` exists before saving any plots:
    ```python
    from pathlib import Path
    Path("{plot_path}").mkdir(parents=True, exist_ok=True)
    ```

    Finish with a print message that summarizes your key insights.
  expected_output: >
    Markdown report with:
      ‚Ä¢ image embeds of saved plots (e.g. <img src="output/plots/correlation_heatmap.png" width="600" />)
      ‚Ä¢ table of top correlations  
      ‚Ä¢ narrative on anomalies or trends
  agent: data_analyst
  context: [clean_data]

# ---------------------------------------------------------------------------
#  4  FEATURE SELECTION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
select_features:
  description: >
    Select the strongest predictors for:

        {request}

    Use:
      ‚Ä¢ `top_correlations` (from EDA)  
      ‚Ä¢ `statistical_notes`

    Decide whether the prediction target is categorical or numeric:
      ‚Üí return `"classification"` or `"regression"`.

    Deliver:
      ‚Ä¢ `top_features` ‚Äì list & rationale  
      ‚Ä¢ `problem_type` ‚Äì classification / regression (+ why)
  expected_output: >
    Markdown brief:
      ‚Äì chosen features + justification  
      ‚Äì inferred problem type + explanation
  agent: data_analyst
  context: [explore_data]

# ---------------------------------------------------------------------------
#  5  MODEL BUILDING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
build_predictive_model:
  description: >
    Train multiple predictive models using the cleaned dataset, 
    compare them, and select the best based on validation performance.

    üõ†Ô∏è Tool to call:
    `build_predictive_model(data=cleaned_path, out_dir="{output_dir}", problem_type=problem_type, tuning=True)`

    ‚úÖ The tool will automatically:
      - Try all appropriate models:
          ‚Ä¢ classification: random_forest, logistic_reg, svm, knn, gbt  
          ‚Ä¢ regression:     random_forest, linear_reg, svm, gbt
      - Run GridSearchCV if `tuning=True` (default off)
      - Pick the best-performing model (F1 or R¬≤)
      - Save:
          ‚Ä¢ `output/model-report.json` (type, target, metrics, plots, summary)  
          ‚Ä¢ `output/technical-metrics.md`  
          ‚Ä¢ Visualizations to `{plot_path}/`
      - Include `all_model_scores` for dashboard bar chart use

    üõë Do **not** hard-code or guess the model name. The tool handles selection.

    For all embedded plots in markdown, use:
    <img src="plots/feature_importances.png" width="600" />
  expected_output: >
    - `output/model-report.json` with selected model, metrics, summary, paths
    - `output/plots/feature_importances.png` (+ confusion_matrix.png if classification)  
    - `output/technical-metrics.md`
  agent: model_builder
  context: [clean_data, select_features]


# ---------------------------------------------------------------------------
#  6  EXECUTIVE SUMMARY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
summarize_findings:
  description: >
    Craft an executive-level summary for non-technical stakeholders.

    Use:
      - `model_type`, `metrics`, `feature_importance_path`, 
      `output/technical-metrics.md` (from model_builder).
      - earlier narratives and outputs if helpful.

    Must include:
      - 2-3 sentence plain-language overview  
      - 3-5 bullet key insights  
      - a one-sentence recommendation  
      - embedded feature-importance image:
          <img src="plots/feature_importances.png" width="600" />
  expected_output: >
    Markdown file `output/final-insight-summary.md` with all of the above.
  agent: insight_reporter
  context: [build_predictive_model]
  output_file: output/final-insight-summary.md

# ---------------------------------------------------------------------------
#  7  LAUNCH DASHBOARD üöÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ---------------------------------------------------------------------------
launch_dashboard:
  description: >
    Launch the Streamlit dashboard by calling the prebuilt tool:
    `launch_dashboard(path="dashboard.py", port=8501)`

    The tool will:
      ‚Ä¢ Start the dashboard server via Streamlit
      ‚Ä¢ Open the browser to the correct local URL
      ‚Ä¢ Print confirmation that the dashboard is live
  expected_output: >
    A message confirming the dashboard URL, e.g.:
    "Dashboard launched on http://localhost:8501"
  agent: insight_reporter
  context: [summarize_findings]
  