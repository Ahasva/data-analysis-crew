# ---------------------------------------------------------------------------
#  1  LOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ---------------------------------------------------------------------------
load_data:
  description: >
    Load the CSV dataset using the exact *literal* path in `{dataset_path}`.
    âš ï¸ Do **not** search or list directories.

    Use pandas to:
      â€¢ read the file  
      â€¢ `print()` shape and column names  
      â€¢ report missing-value counts and inferred dtypes  

    Dataset Path (string): **{dataset_path}**
  expected_output: >
    - Dataset shape  
    - `dtype_map` (column â†’ dtype)  
    - `missing_values` (column â†’ #missing)  
    - Path actually read/written
  agent: data_engineer

# ---------------------------------------------------------------------------
#  2  CLEAN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ---------------------------------------------------------------------------
clean_data:
  description: >
    Tidy up the raw dataset.

    â€¢ Call the tool:
      `load_or_clean(raw_path="{dataset_path}", cleaned_path="knowledge/diabetes_cleaned.csv")`
    â€¢ If the cleaned file exists, itâ€™ll be re-used.
    â€¢ If **knowledge/diabetes_cleaned.csv** exists â†’ just load it, gather
      metadata, and return â€“ **do not** re-clean.  
    â€¢ Else â†’ read **knowledge/diabetes.csv**, normalise column names
      (lower-snake-case), fix missing values / constants, then save to the
      same cleaned path.

    Always `print()` the cleaned file path as **the first line of STDOUT** so
    the Code-Interpreter tool captures it.

    Helper available:

    ```python
    from data_analysis_crew.tools import load_or_clean
    df = load_or_clean()            # â† re-uses cache or cleans afresh
    ```

    After cleaning assemble the `CleanedDataOutput` fields:
      â€¢ cleaned_path  
      â€¢ final_features / numeric_features / categorical_features  
      â€¢ dropped_columns / imputation_summary
  expected_output: >
    1  First STDOUT line â†’ `knowledge/diabetes_cleaned.csv`  
    2  Markdown block:
       â€“ cleaning steps  
       â€“ final feature Ã— dtype table  
       â€“ post-clean missing-value summary
  agent: data_engineer
  context: [load_data]

# ---------------------------------------------------------------------------
#  3  EXPLORE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ---------------------------------------------------------------------------
explore_data:
  description: >
    Perform an exploratory analysis of the cleaned dataset.

    Inputs (already in context):
      â€¢ Cleaned file â†’ `cleaned_path`  
      â€¢ Numeric cols â†’ `numeric_features`  
      â€¢ Categorical â†’ `categorical_features`

    When you call the Code Interpreter, include
    {
      "code": "
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    from pathlib import Path

    df = pd.read_csv('knowledge/diabetes_cleaned.csv')

    # 1) Descriptive statistics
    stats = df.describe().to_string()
    print(stats)

    # 2) Example plot directory
    plots_dir = Path('output/plots'); plots_dir.mkdir(parents=True, exist_ok=True)

    # Histogram for each numeric column
    for col in df.select_dtypes('number').columns:
        df[col].hist()
        plt.title(col)
        filename = "{}_hist.png".format(col)
        plt.savefig(plots_dir / filename)
        plt.clf()

    # 3) Correlation heat-map
    plt.figure(figsize=(8,6))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
    plt.tight_layout()
    heat_path = plots_dir / 'correlation_heatmap.png'
    plt.savefig(heat_path)
    print("Heat-map saved â†’ {}".format(heat_path))

    # ALWAYS finish with a print so the tool
    # has something to capture as â€œfinal resultâ€
    print('EDA script finished')
    ",
      "libraries_used": ["pandas", "matplotlib", "seaborn"]
    }.

    Tasks:
      1. Descriptive statistics (`df.describe()`; include categoricals)  
      2. Visualise distributions / relationships  
      3. Compute correlation matrix, list the top correlations with the target,
         flag outliers & anomalies.

    You **must** save **â‰¥ 3** PNGs into **{output_dir}/plots/**.
  expected_output: >
    Markdown report with:
      â€¢ embeds / links for the saved plots  
      â€¢ table of top correlations  
      â€¢ notes on anomalies / biases / outliers
  agent: data_analyst
  context: [clean_data]

# ---------------------------------------------------------------------------
#  4  FEATURE SELECTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ---------------------------------------------------------------------------
select_features:
  description: >
    Select the strongest predictors for:

        {request}

    Use:
      â€¢ `top_correlations` (from EDA)  
      â€¢ `statistical_notes`

    Decide whether the prediction target is categorical or numeric:
      â†’ return `"classification"` or `"regression"`.

    Deliver:
      â€¢ `top_features` â€“ list & rationale  
      â€¢ `problem_type` â€“ classification / regression (+ why)
  expected_output: >
    Markdown brief:
      â€“ chosen features + justification  
      â€“ inferred problem type + explanation
  agent: data_analyst
  context: [explore_data]

# ---------------------------------------------------------------------------
#  5  MODEL BUILDING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ---------------------------------------------------------------------------
build_predictive_model:
  description: >
    Train a model on the cleaned dataset and save every artefact the
    dashboard needs.

    **Call the helper tool**  
      `build_predictive_model(df, out_dir="{output_dir}", problem_type=problem_type)`  
    that lives in **data_analysis_crew.tools**.

    The tool will:
      â€¢ train an appropriate model  
      â€¢ save `output/model-report.json`  
      â€¢ save plots to `output/plots/`  
      â€¢ write `output/final-insight-summary.md`

    Ensure the dashboard can find everything (all paths **relative**).

    Only hand-code training (i.e. build ML models), if the invoked tool does not work
    or does not lead to meaningful, data-related insights.
    Usually invoking the helper tool (build_predictive_model) is enough.

    Example for metrics:
    â€¢ If `problem_type == classification` â†’ `RandomForestClassifier`  
      (report *accuracy* & *F1*).  
    â€¢ Else â†’ `RandomForestRegressor`  
      (report *RÂ²* & *MSE*).
    Be explicit and use metrics, if it makes sense. 

    Required outputs (all **relative paths**) in `{output_dir}`:

      â”Œ output/model-report.json
      â”‚   â”œâ”€ model_type
      â”‚   â”œâ”€ target
      â”‚   â”œâ”€ metrics {accuracy/F1 or RÂ²/MSE}
      â”‚   â”œâ”€ plain_summary      (one-liner for the dashboard)
      â”‚   â”œâ”€ feature_importance_path   â†’  plots/feature_importances.png
      â”‚   â””â”€ confusion_matrix_path     â†’  plots/confusion_matrix.png
      â”” output/plots/
          â”œâ”€ feature_importances.png
          â””â”€ confusion_matrix.png      (only for classifiers)

    **Important**: create the `output/plots/` directory when missing.

    Also write a short Markdown block to `output/final-insight-summary.md`
    embedding the *relative* feature-importance image.
  expected_output: >
    - A brief Markdown summary with final metrics and the plot.
    - `output/model-report.json` (with metrics, paths, summary).  
    - `output/plots/feature_importances.png` (+ `confusion_matrix.png` if cls).
    - Short Markdown summary in `output/final-insight-summary.md` with all meaningful insight, metrics and plots.
  agent: model_builder
  context: [clean_data, select_features]
  output_file: output/model-report.json



# ---------------------------------------------------------------------------
#  6  EXECUTIVE SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ---------------------------------------------------------------------------
summarize_findings:
  description: >
    Craft an executive-level summary for non-technical stakeholders.

    Use:
      â€¢ `model_type`, `metrics`, `feature_importance_path`  
      â€¢ earlier narratives if useful.

    Must include:
      â€¢ 2-3 sentence plain-language overview  
      â€¢ 3-5 bullet key insights  
      â€¢ a one-sentence recommendation  
      â€¢ embedded feature-importance image:

          ![Feature Importances](`feature_importance_path`)
  expected_output: >
    Markdown file `output/final-insight-summary.md` with all of the above.
  agent: insight_reporter
  context: [build_predictive_model]
  output_file: output/final-insight-summary.md


# ---------------------------------------------------------------------------
#  7  LAUNCH DASHBOARD ðŸš€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ---------------------------------------------------------------------------
launch_dashboard:
  description: >
    Spin-up the Streamlit dashboard (dashboard.py) **after** the executive
    summary is written.  
    Steps  
      â€¢ run:  streamlit run dashboard.py  
      â€¢ wait 3 s, then open the browser on http://localhost:8501  
      â€¢ return a short confirmation string
  expected_output: >
    A message confirming the dashboard URL, e.g.:
    "Dashboard launched on http://localhost:8501"
  agent: data_project_manager
  context: [summarize_findings]