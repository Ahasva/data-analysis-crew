load_data:
  description: >
    Load the CSV dataset using the exact path provided in `{dataset_path}`.
    ⚠️ Do NOT attempt to search or list any directories.
    
    Use pandas to:
    - Load the dataset from the given path
    - Print the dataset shape and column names
    - Report missing values and inferred column types
    - Save a snapshot CSV if any changes were applied

    Dataset Path: {dataset_path}
  expected_output: >
    A summary report including:
    - Dataset shape
    - List of column names and inferred data types (as dtype_map)
    - Count of missing values per column (as missing_values)
    - Save path of the loaded dataset file (if modified)
  agent: data_engineer

clean_data:
  description: >
    Clean and preprocess the raw dataset previously loaded.

    - If **knowledge/diabetes_cleaned.csv** already exists, just load it,
      collect metadata, and return the path – **do not re-clean**.  
    - Otherwise:  
        • Read **knowledge/diabetes.csv**  
        • Normalise column names to lower-snake-case  
        • Handle missing values, drop constants, etc.  
        • Save the result as **knowledge/diabetes_cleaned.csv**  
    - Always `print()` the cleaned file path as the *first* line of
      stdout so the Code-Interpreter tool can capture it.

    Use the helper:

    ```python
    from data_analysis_crew.tools import load_or_clean
    df = load_or_clean()
    ```

    After that, assemble and return all fields required by
    **CleanedDataOutput** (cleaned_path, final_features,
    numeric_features, categorical_features, dropped_columns,
    imputation_summary).

  expected_output: >
    • First line printed = absolute or relative path to
      **knowledge/diabetes_cleaned.csv**  
    • Plus a Markdown summary containing:  
        – Cleaning steps taken  
        – Final feature list with dtypes  
        – Missing-value summary after cleaning  

  agent: data_engineer
  context: [load_data]

explore_data:
  description: >
    Perform an exploratory analysis of the cleaned dataset.

    Dataset Path: `cleaned_path`
    Numeric Features: `numeric_features`
    Categorical Features: `categorical_features`
    Output Directory: {output_dir}

    Tasks:
    - Calculate descriptive statistics
    - Visualize distributions and relationships
    - Identify top correlations and potential outliers

    Save at least 3 plots to {output_dir}/plots.
  expected_output: >
    A Markdown report with:
    - At least 3 plots saved to {output_dir}/plots
    - A table of top correlations with the target
    - Notes on potential biases, anomalies, or outliers
  agent: data_analyst
  context: [clean_data]

select_features:
  description: >
    From the prior exploratory analysis, select the most important features related to the question:

    {request}

    Use the following inputs:
    - Correlation Matrix: `top_correlations`
    - Statistical Notes: `statistical_notes`

    Also determine whether the prediction target is:
    - Categorical → classification
    - Numeric → regression

    Return:
    - A list of selected features
    - Inferred problem type
    - Explanation for choices
  expected_output: >
    A Markdown summary with:
    - A list of top features with brief justification
    - The inferred problem type ("classification" or "regression")
    - Justification for problem type choice
  agent: data_analyst
  context: [explore_data]

build_predictive_model:
  description: >
    Use the cleaned dataset to train a predictive model.

    Dataset Path: `cleaned_path`
    Features: `top_features`
    Problem Type: `problem_type`
    Request: {request}
    Output Directory: {output_dir}

    Task:
    - If classification, use RandomForestClassifier
    - If regression, use RandomForestRegressor

    Split data, train the model, evaluate using:
    - Accuracy, F1 Score (for classification)
    - R², MSE (for regression)

    Save:
    - Feature importance plot to {output_dir}/plots/feature_importances.png
    - Confusion matrix if applicable
  expected_output: >
    A Markdown report with:
    - Final metrics (accuracy/F1 or R²/MSE)
    - A plot of feature importances saved to {output_dir}/plots/feature_importances.png
    - Summary table of training results
    Formatted as markdown without "```"
  agent: model_builder
  context: [clean_data, select_features]
  output_file: output/model-report.json

summarize_findings:
  description: >
    Write a high-level executive summary of the analysis.

    Model: `model_type`
    Metrics: `metrics`
    Feature Importances: ![Feature Importances](`feature_importance_path`)

    Focus on:
    - Key features that influence the outcome
    - Interpretation of model performance
    - Actionable business insights

    Add a plain-language executive summary for non-technical stakeholders:
    - Explain what the model does in 2–3 sentences
    - Clearly state what feature(s) matter most
    - Describe the model's confidence and limitations
    - Provide a single-sentence recommendation based on findings

    Include 3–5 bullet points and a final recommendation section.
    Include a visual:
    ![Feature Importances](plots/feature_importances.png)

  expected_output: >
    A Markdown executive summary with:
    - A plain-language summary for executives (2–3 sentences)
    - 3–5 bullet points highlighting key insights
    - A conclusion section with takeaways and a recommendation
    - Embedded plot image(s)
    - Highlight any assumptions or limitations
  agent: insight_reporter
  context: [build_predictive_model]
  output_file: output/final-insight-summary.md